{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* `Importing modules`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOMt7YYOPWQG",
        "outputId": "9c4aeae3-c0cd-4321-b720-877f5e241430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import VGG16_Weights\n",
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "# !pip install torchmetrics\n",
        "# from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
        "from scipy import linalg\n",
        "from torchvision import models\n",
        "from torch import optim\n",
        "import scipy.io as sio\n",
        "from tqdm import tqdm\n",
        "from scipy.ndimage import zoom\n",
        "import glob\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "from torchvision.models.inception import inception_v3, Inception_V3_Weights\n",
        "import uuid\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from scipy import linalg\n",
        "import torchvision.transforms.functional as TF\n",
        "from tqdm import tqdm\n",
        "\n",
        "# tiny-imagenet-200 dataset paths\n",
        "COVER_DIR = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"tiny-imagenet-200\", \"Tiny_imageNet\", \"val\", \"images\")\n",
        "SECRET_DIR = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"tiny-imagenet-200\", \"Tiny_imageNet\", \"test\", \"images\")\n",
        "EDGE_DIR_OUTPUT = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"data\", \"hed_predictions\")\n",
        "EDGE_DIR_OUTPUT_3 = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"data\", \"hed_predictions_3\")\n",
        "EDGE_DIR_OUTPUT_4 = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"data\", \"hed_predictions_4\")\n",
        "EDGE_DIR_OUTPUT_5 = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"data\", \"hed_predictions_5\")\n",
        "\n",
        "\n",
        "# bsds\n",
        "COVER_DIR_TRAIN = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"BSDS500\", \"images\", \"train\" )\n",
        "COVER_DIR_TEST = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"BSDS500\", \"images\", \"test\")\n",
        "COVER_DIR_VAL = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"BSDS500\", \"images\", \"val\" )\n",
        "EDGE_DIR_TRAIN = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"data\", \"jpg_edge_images\", \"train\")\n",
        "gt_dir = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"BSDS500\", \"groundTruth\", \"train\")\n",
        "\n",
        "# Model weights\n",
        "CHECKPOINT_DIR = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"artifacts\")\n",
        "DATA_DIR = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"data\")\n",
        "\n",
        "# GANs\n",
        "CGANS_CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"cGANs_checkpoint_83.pth\")\n",
        "CGANS_OUTPUT_DIR = os.path.join(DATA_DIR, \"hed_cGANs\")\n",
        "\n",
        "# CNN\n",
        "HIDING_NET_PATH = os.path.join(CHECKPOINT_DIR, \"hiding_net.pth\")\n",
        "REVEAL_NET_PATH = os.path.join(CHECKPOINT_DIR, \"reveal_net.pth\")\n",
        "\n",
        "# Genetics\n",
        "GENETIC_HED_PATH = os.path.join(CHECKPOINT_DIR, \"hed_genetic.pth\")\n",
        "GENETIC_OUTPUT_DIR = os.path.join(os.getcwd(), \"drive\", \"MyDrive\", \"image steganography\", \"data\", \"genetic_predictions\")\n",
        "\n",
        "# CNN results paths\n",
        "HED_RESULTS = os.path.join(DATA_DIR,  \"hed_results\")\n",
        "STEGO_DIR = os.path.join(HED_RESULTS, \"CNN_stego\")\n",
        "DECODED_DIR = os.path.join(HED_RESULTS, \"CNN_decoded\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "# os.makedirs(SECRET_DIR, exist_ok=True)\n",
        "# os.makedirs(SECRET_DIR2, exist_ok=True)\n",
        "\n",
        "# os.makedirs(DATA_EDGE_DIR, exist_ok=True)\n",
        "# os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tnqxnt-TPa-p"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torchmetrics\n",
        "!pip install opencv-contrib-python\n",
        "!git clone https://github.com/s9xie/hed.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5bIukwWPdbj",
        "outputId": "325260d5-d371-40f0-b5dd-7ae11df0c226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c9JZMrqPeHj"
      },
      "outputs": [],
      "source": [
        "def process_hed_with_dataloader(net, data_loader, out_dir, threshold=0.12):\n",
        "    \"\"\"\n",
        "    Process images from a dataloader through HED edge detection model\n",
        "\n",
        "    Args:\n",
        "        net: The HED Caffe model loaded with cv2.dnn\n",
        "        data_loader: DataLoader containing images\n",
        "        out_dir: Directory to save edge maps\n",
        "        threshold: Threshold for edge detection\n",
        "    \"\"\"\n",
        "    # Make sure output directory exists\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Process each batch\n",
        "    total_processed = 0\n",
        "    for batch_data in tqdm(data_loader, desc=\"Processing HED edges\"):\n",
        "        # Unpack the batch\n",
        "        images, numeric_ids, img_paths = batch_data\n",
        "\n",
        "        # Process each image in the batch\n",
        "        for i in range(len(images)):\n",
        "            # Convert PyTorch tensor to numpy array for OpenCV\n",
        "            if torch.is_tensor(images[i]):\n",
        "                img = images[i].permute(1, 2, 0).numpy()  # Convert from CxHxW to HxWxC\n",
        "                img = (img * 255).astype(np.uint8)  # Scale from [0,1] to [0,255]\n",
        "            else:\n",
        "                # If it's already a PIL Image or numpy array\n",
        "                img = np.array(images[i])\n",
        "\n",
        "            # Get original dimensions before any processing\n",
        "            orig_h, orig_w = img.shape[:2]\n",
        "\n",
        "            # Resize for HED model\n",
        "            resized = cv2.resize(img, (321, 481))\n",
        "\n",
        "            # Create blob for the network\n",
        "            blob = cv2.dnn.blobFromImage(\n",
        "                resized,\n",
        "                scalefactor=1.0,\n",
        "                size=(321, 481),\n",
        "                mean=(104.00699, 116.66877, 122.67892),\n",
        "                swapRB=True,  # convert from cv2's BGR to the RGB ordering used in training (so that caffe sees BGR)\n",
        "                crop=False\n",
        "              )\n",
        "\n",
        "            # Forward pass through the network\n",
        "            net.setInput(blob)\n",
        "            hed = net.forward()\n",
        "            hed = hed[0, 0]  # Shape: (height, width), values in [0, 1]\n",
        "\n",
        "            # Threshold to keep only strong edges\n",
        "            hed_binary = (hed > threshold).astype(np.uint8)  # Binary map: 0 or 1\n",
        "\n",
        "            # Thin the edges using morphological skeletonization\n",
        "            hed_thinned = cv2.ximgproc.thinning(hed_binary * 255)  # Thinning requires 0 or 255\n",
        "            hed_thinned = (hed_thinned > 0).astype(np.uint8)  # Back to 0 or 1\n",
        "\n",
        "            # Resize to original dimensions\n",
        "            hed_resized = cv2.resize(hed_thinned, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            # Convert to 0-255 for PNG saving\n",
        "            hed_final = (hed_resized * 255).astype(\"uint8\")\n",
        "\n",
        "            # Save edge map using numeric ID if available, otherwise use original filename\n",
        "\n",
        "            if numeric_ids[i]:\n",
        "                save_name = f\"{numeric_ids[i]}.jpg\"\n",
        "            else:\n",
        "                # Extract base name without extension\n",
        "                filename = os.path.splitext(os.path.basename(img_paths[i]))[0]\n",
        "                save_name = f\"{filename}.jpg\"\n",
        "\n",
        "            cv2.imwrite(os.path.join(out_dir, save_name), hed_final)\n",
        "            total_processed += 1\n",
        "\n",
        "    print(f\"✅ Processed {total_processed} images. All HED outputs saved to: {out_dir}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIyKG4O-n9ZY"
      },
      "outputs": [],
      "source": [
        "class BSDS500Dataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset for BSDS500 images (test split).\n",
        "    Assumes images in <bsds_path>/images/test and ground truths in <bsds_path>/groundTruth/test\n",
        "    \"\"\"\n",
        "    def __init__(self, bsds_path, transform=None):\n",
        "        self.img_dir = os.path.join(bsds_path)\n",
        "        # self.gt_dir = os.path.join(bsds_path, 'groundTruth', 'test')\n",
        "        self.img_paths = sorted(glob(os.path.join(self.img_dir, '*.jpg')))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, img_path\n",
        "\n",
        "# # Dataset & Dataloader\n",
        "# def cv_transform(pil_img):\n",
        "#     # Resize to 321x481 (width x height) as in HED\n",
        "#     resized = pil_img.resize((321, 481), Image.BILINEAR)\n",
        "#     return np.array(resized)\n",
        "\n",
        "# dataset = BSDS500Dataset(COVER_DIR_TRAIN, transform=cv_transform)\n",
        "# loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "# len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DId7Gba9amil"
      },
      "outputs": [],
      "source": [
        "def process_with_dataloader(proto, model, bsds_path, out_dir, batch_size=4, use_cuda=False):\n",
        "    # Load network\n",
        "    net = cv2.dnn.readNetFromCaffe(proto, model)\n",
        "    if use_cuda:\n",
        "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((481, 321)),  # HED expects height×width as 481×321\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    dataset = BSDS500Dataset(bsds_path, transform=transform)\n",
        "    loader = DataLoader(dataset, batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    saved_paths = []\n",
        "\n",
        "    # Process\n",
        "    for batch in tqdm(loader, desc='HED inference'):\n",
        "        imgs, paths = batch\n",
        "        for img_tensor, path in zip(imgs, paths):\n",
        "            # img_np: HxWxC, uint8, RGB\n",
        "            # Prepare blob: swapRB=True to convert RGB->BGR as Caffe expects\n",
        "\n",
        "            img_np = img_tensor.permute(1, 2, 0).numpy()\n",
        "            # Scale from [0, 1] float to [0, 255] uint8\n",
        "            img_np = (img_np * 255).astype(np.uint8)\n",
        "\n",
        "            blob = cv2.dnn.blobFromImage(\n",
        "                img_np,\n",
        "                scalefactor=1.0,\n",
        "                size=(321, 481),\n",
        "                mean=(104.00699, 116.66877, 122.67892),\n",
        "                swapRB=True,\n",
        "                crop=False\n",
        "            )\n",
        "            net.setInput(blob)\n",
        "            hed = net.forward()\n",
        "            # hed shape: (1,1,H,W)\n",
        "            hed_map = hed[0,0,:,:]\n",
        "            # Scale to [0,255]\n",
        "            hed_uint8 = (hed_map * 255).astype(np.uint8)\n",
        "\n",
        "            # Save as PNG with same basename\n",
        "            base = os.path.splitext(os.path.basename(path))[0]\n",
        "            out_path = os.path.join(out_dir, base + '.png')\n",
        "            cv2.imwrite(out_path, hed_uint8)\n",
        "            saved_paths.append(out_path)\n",
        "\n",
        "    return saved_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* `Inference`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSPkx9Fbo0Wz",
        "outputId": "877da1f9-7616-40a7-f092-2726d3e82162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting HED inference...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "HED inference: 100%|██████████| 50/50 [05:24<00:00,  6.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 200 edge maps to /content/drive/MyDrive/image steganography/data/hed_predictions_3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# HED model\n",
        "proto = \"/content/hed/examples/hed/deploy.prototxt\"\n",
        "caffe = os.path.join(CHECKPOINT_DIR, \"hed_pretrained_bsds.caffemodel\")\n",
        "net = cv2.dnn.readNetFromCaffe(proto, caffe)\n",
        "\n",
        "# Run inference and save probability maps\n",
        "print(\"Starting HED inference...\")\n",
        "saved = process_with_dataloader(\n",
        "    proto,caffe, COVER_DIR_TRAIN,EDGE_DIR_OUTPUT_3,\n",
        "    batch_size=4\n",
        ")\n",
        "print(f\"Saved {len(saved)} edge maps to {EDGE_DIR_OUTPUT_3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__5wTY-J62qn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def nms_and_binarize_edges(input_dir, output_dir, threshold=0.2):\n",
        "    \"\"\"\n",
        "    Applies threshold and Non-Maximum Suppression to HED outputs.\n",
        "\n",
        "    Args:\n",
        "        input_dir: Path to raw HED output images (float edge maps).\n",
        "        output_dir: Where to save binarized, NMS-processed edges.\n",
        "        threshold: Float threshold for binarization (0-1).\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    edge_files = sorted([\n",
        "        f for f in os.listdir(input_dir)\n",
        "        if f.endswith('.png') or f.endswith('.jpg')\n",
        "    ])\n",
        "\n",
        "    for file in tqdm(edge_files, desc=\"Applying NMS & binarization\"):\n",
        "        path = os.path.join(input_dir, file)\n",
        "        edge_map = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Normalize if needed\n",
        "        if edge_map.max() > 1:\n",
        "            edge_map = edge_map.astype(np.float32) / 255.0\n",
        "\n",
        "        # Apply threshold\n",
        "        binary = (edge_map > threshold).astype(np.uint8) * 255\n",
        "\n",
        "        # Apply thinning (OpenCV's morphological thinning)\n",
        "        thinned = cv2.ximgproc.thinning(binary)\n",
        "\n",
        "        # Save result\n",
        "        save_path = os.path.join(output_dir, file)\n",
        "        cv2.imwrite(save_path, thinned)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjdo1vWK_e_x",
        "outputId": "a4ee62b2-7ce0-4a4f-ac2c-e472241aedbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Applying NMS & binarization: 100%|██████████| 200/200 [00:12<00:00, 15.79it/s]\n"
          ]
        }
      ],
      "source": [
        "nms_and_binarize_edges(EDGE_DIR_OUTPUT_3, EDGE_DIR_OUTPUT_5, threshold=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VITrvXRF_3Tm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
